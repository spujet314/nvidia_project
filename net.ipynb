{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this code to initialize model functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST('/files/', train=True, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor()])),batch_size=60000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = next(enumerate(train_loader))[1][0]\n",
    "std,mean=torch.std_mean(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST('/files/', train=True, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((mean,),(std,))])),batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader( torchvision.datasets.MNIST('/files/', train=False, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((mean,),(std,))])),batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__()\n",
    "    self.Conv1=nn.Conv2d(1,10,kernel_size=5)\n",
    "    self.Conv2=nn.Conv2d(10,20,kernel_size=5)\n",
    "    self.ConvDrop=nn.Dropout2d()\n",
    "    self.Full1=nn.Linear(320,50)\n",
    "    self.Full2=nn.Linear(50,10)\n",
    "  def forward(self,x):\n",
    "    x=self.Conv1(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x=F.relu(x)\n",
    "    x=self.Conv2(x)\n",
    "    x=F.relu(x)\n",
    "    x=self.ConvDrop(x)\n",
    "    x = F.max_pool2d(x, 2)\n",
    "    x=F.relu(x)\n",
    "    x = x.view(-1, 320)\n",
    "    x=self.Full1(x)\n",
    "    x=F.relu(x)\n",
    "    x=self.Full2(x)\n",
    "    x=F.log_softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net()\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    count=True\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3\n",
    "log_interval = 10\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "      torch.save(network.state_dict(), 'results/model.pth')\n",
    "      torch.save(optimizer.state_dict(), 'results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code the first time, to initialize and train the model with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera\n",
    "\n",
    "<div style=\"border:2px solid black; background-color:#e3ffb3; font-size:12px; padding:8px; margin-top: auto;\">\n",
    "    <h4><i>Tip</i></h4>\n",
    "    <p>There can only be one instance of CSICamera or USBCamera at a time.  Before starting this notebook, make sure you have executed the final \"shutdown\" cell in any other notebooks you have run so that the camera is released. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crw-rw---- 1 root video 81, 0 Jul 19 00:03 /dev/video0\n"
     ]
    }
   ],
   "source": [
    "# Check device number\n",
    "!ls -ltrh /dev/video*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera created\n"
     ]
    }
   ],
   "source": [
    "from jetcam.usb_camera import USBCamera\n",
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "# for USB Camera (Logitech C270 webcam), uncomment the following line\n",
    "camera = USBCamera(width=224, height=224, capture_device=0) # confirm the capture_device number\n",
    "\n",
    "# for CSI Camera (Raspberry Pi Camera Module V2), uncomment the following line\n",
    "# camera = CSICamera(width=224, height=224, capture_device=0) # confirm the capture_device number\n",
    "\n",
    "camera.running = True\n",
    "print(\"camera created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numbers task with ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] categories defined\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from dataset import ImageClassificationDataset\n",
    "\n",
    "TASK = 'numbers'\n",
    "\n",
    "CATEGORIES = ['0','1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "DATASETS = ['A', 'B']\n",
    "\n",
    "TRANSFORMS = transforms.Compose([\n",
    "    transforms.Resize((28,28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485], [0.229])\n",
    "])\n",
    "\n",
    "datasets = {}\n",
    "for name in DATASETS:\n",
    "    datasets[name] = ImageClassificationDataset('./data/' + TASK + '_' + name, CATEGORIES, TRANSFORMS)\n",
    "    \n",
    "print(\"{} task with {} categories defined\".format(TASK, CATEGORIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data directory location if not there already\n",
    "DATA_DIR = '/nvdli-nano/project/data'\n",
    "!mkdir -p {DATA_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_collection_widget created\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets\n",
    "import traitlets\n",
    "from IPython.display import display\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import numpy\n",
    "\n",
    "# initialize active dataset\n",
    "dataset = datasets[DATASETS[0]]\n",
    "\n",
    "# unobserve all callbacks from camera in case we are running this cell for second time\n",
    "camera.unobserve_all()\n",
    "\n",
    "# create image preview\n",
    "camera_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# create widgets\n",
    "dataset_widget = ipywidgets.Dropdown(options=DATASETS, description='dataset')\n",
    "category_widget = ipywidgets.Dropdown(options=dataset.categories, description='category')\n",
    "count_widget = ipywidgets.IntText(description='count')\n",
    "save_widget = ipywidgets.Button(description='add')\n",
    "\n",
    "# manually update counts at initialization\n",
    "count_widget.value = dataset.get_count(category_widget.value)\n",
    "\n",
    "# sets the active dataset\n",
    "def set_dataset(change):\n",
    "    global dataset\n",
    "    dataset = datasets[change['new']]\n",
    "    count_widget.value = dataset.get_count(category_widget.value)\n",
    "dataset_widget.observe(set_dataset, names='value')\n",
    "\n",
    "# update counts when we select a new category\n",
    "def update_counts(change):\n",
    "    count_widget.value = dataset.get_count(change['new'])\n",
    "category_widget.observe(update_counts, names='value')\n",
    "\n",
    "# save image for category and update counts\n",
    "def save(c):\n",
    "    img = camera.value\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    img = torchvision.transforms.functional.rgb_to_grayscale(img,1)\n",
    "    img = torchvision.transforms.Resize((28,28))(img)\n",
    "    img = torchvision.transforms.functional.invert(img)\n",
    "    img= torchvision.transforms.functional.adjust_contrast(img,10)\n",
    "    img = numpy.array(img)\n",
    "    dataset.save_entry(img, category_widget.value)\n",
    "    count_widget.value = dataset.get_count(category_widget.value)\n",
    "save_widget.on_click(save)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget]), dataset_widget, category_widget, count_widget, save_widget\n",
    "])\n",
    "\n",
    "# display(data_collection_widget)\n",
    "print(\"data_collection_widget created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model configured and model_widget created\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "# model = model.to(device)\n",
    "network=Net()\n",
    "checkpoint=torch.load('results/model.pth')\n",
    "network.load_state_dict(checkpoint)\n",
    "\n",
    "model_save_button = ipywidgets.Button(description='save model')\n",
    "model_load_button = ipywidgets.Button(description='load model')\n",
    "model_path_widget = ipywidgets.Text(description='model path', value='/nvdli-nano/project/results/my_model.pth')\n",
    "\n",
    "network.cuda()\n",
    "\n",
    "def load_model(c):\n",
    "    network.load_state_dict(torch.load(model_path_widget.value))\n",
    "model_load_button.on_click(load_model)\n",
    "    \n",
    "def save_model(c):\n",
    "    torch.save(network.state_dict(), model_path_widget.value)\n",
    "model_save_button.on_click(save_model)\n",
    "\n",
    "model_widget = ipywidgets.VBox([\n",
    "    model_path_widget,\n",
    "    ipywidgets.HBox([model_load_button, model_save_button])\n",
    "])\n",
    "\n",
    "# display(model_widget)\n",
    "print(\"model configured and model_widget created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live  Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "live_execution_widget created\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import PIL.Image\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "prediction_widget = ipywidgets.Text(description='prediction')\n",
    "mean=torch.Tensor([0.485]).cuda()\n",
    "std = torch.Tensor([0.229]).cuda()\n",
    "def live(state_widget, model, camera, prediction_widget):\n",
    "    global dataset\n",
    "    count=0\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        image = PIL.Image.fromarray(image)\n",
    "        image = torchvision.transforms.functional.rgb_to_grayscale(image,1)\n",
    "        image = torchvision.transforms.Resize((28,28))(image)\n",
    "        image = torchvision.transforms.functional.invert(image)\n",
    "        image= torchvision.transforms.functional.adjust_contrast(image,10)\n",
    "        image = torchvision.transforms.functional.to_tensor(image).to(device)\n",
    "        image.sub(mean[:]).div_(std[:])\n",
    "        image = image[None, ...]\n",
    "        output = network(image)\n",
    "        category_index = output.data.max(1, keepdim=True)[1]\n",
    "        prediction_widget.value = dataset.categories[category_index]\n",
    "        time.sleep(0.25)\n",
    "\n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, network, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "# display(live_execution_widget)\n",
    "print(\"live_execution_widget created\")\n",
    "state_widget.value = 'live'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training widget created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "epochs_widget = ipywidgets.IntText(description='epochs', value=1)\n",
    "train_button = ipywidgets.Button(description='train')\n",
    "loss_widget = ipywidgets.FloatText(description='loss')\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "log_interval = 2\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(epochs_widget.value + 1)]\n",
    "\n",
    "def train_eval(is_training):\n",
    "    global BATCH_SIZE, learning_rate, momentum, network, dataset, optimizer, train_button, loss_widget, state_widget, epochs_widget\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "    state_widget.value = 'stop'\n",
    "    train_button.disabled = True\n",
    "    time.sleep(1)\n",
    "    if is_training:\n",
    "        network = network.train()\n",
    "    else:\n",
    "        network = network.eval()\n",
    "    while epochs_widget.value > 0:\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                loss_widget.value = loss.item()\n",
    "                train_losses.append(loss.item())\n",
    "                train_counter.append((batch_idx*64) + ((epochs_widget.value-1)*len(train_loader.dataset)))\n",
    "                torch.save(network.state_dict(), 'results/model.pth')\n",
    "                torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n",
    "        epochs_widget.value-=1\n",
    "    train_button.disabled = False\n",
    "    state_widget.value = 'live'\n",
    "train_button.on_click(lambda c: train_eval(is_training=True))\n",
    "\n",
    "train_eval_widget = ipywidgets.VBox([\n",
    "    epochs_widget,\n",
    "    loss_widget,\n",
    "    ipywidgets.HBox([train_button])\n",
    "])\n",
    "print(\"training widget created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Interactive Tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interactive tool includes widgets for data collection, training, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7658e292e770433589c751828cbccd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(HBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Combine all the widgets into one display\n",
    "all_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([data_collection_widget, live_execution_widget]), \n",
    "    train_eval_widget,\n",
    "    model_widget\n",
    "])\n",
    "\n",
    "display(all_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "image = camera.value\n",
    "image=PIL.Image.fromarray(image)\n",
    "print(type(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#76b900;\"></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you go...<br><br>Shut down the camera and/or notebook kernel to release the camera resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention!  Execute this cell before moving to another notebook\n",
    "# The USB camera application only requires that the notebook be reset\n",
    "# The CSI camera application requires that the 'camera' object be specifically released\n",
    "\n",
    "import os\n",
    "import IPython\n",
    "\n",
    "if type(camera) is CSICamera:\n",
    "    print(\"Ignore 'Exception in thread' tracebacks\\n\")\n",
    "    camera.cap.release()\n",
    "\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return to the DLI course pages for the next instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
